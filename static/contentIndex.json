{"index":{"slug":"index","filePath":"index.md","title":"Welcome ðŸ‘‹","links":[],"tags":[],"content":"Hello. My name is Shane McDonald. I\nlive in Jersey City NJ with my lovely wife Chao, along with our cat Milla and\nour dog Rodger. I am currently employed by Red Hat as\none of the lead engineers for Ansible.\nI created this website to serve as a place where I can capture my thoughts, and\nto have a place where I can reflect on what I learn over the years. I spend a\nlot of my free time trying to find the balance between embracing cutting edge\ntechnology and living a simple life. Lately I have been trying avoid social\nmedia and attempting to maximize the time I spend thinking my own thoughts.\nI am a big fan of Emacs and\nFedora, and I very much believe that open source\nsoftware has made the world a better place, and I am proud to do my part in\ncontinuing that mission.\nIf you would like to connect, my email is on my\nGitHub profile.\nHave a nice day."},"posts/01-my-first-post":{"slug":"posts/01-my-first-post","filePath":"posts/01-my-first-post.md","title":"My first post","links":[],"tags":[],"content":"Why I made this website\nItâ€™s been a while since I had the time or cared enough to maintain a website for\nmyself. As a software engineer, I found that over time I gradually lost interest\nin using a computer outside of work.\nThat made me sad, because I am truly grateful to be paid to do something that I\nhad at one point spent countless hours doing in my free time. After enough time\nhad passed, I began to reflect on the situation and try and start to understand\nwhat had happened. The answer seems simple now - I had stopped learning for the\nsake of learning.\nWhen acquiring new a new skill, almost every day is filled with\nfirst-encounters. Especially so with programming. The amount of information\nrequired to begin understanding how software interacts with underlying physical\nhardware is more than enough to keep you busy for multiple lifetimes. But people\ntend to achieve a level of proficiency that allows them to carry out the task at\nhand and then stop learning.\nThis is understandable - thereâ€™s only so many hours in the day and there are\nother things in life to care about. Itâ€™s largely what happened to me. Once I\nstarted making enough money to pay the bills and support my family, I felt less\nof a need to learn things outside of what it took to accomplish the immediate\ntasks at hand at work.\nWriting code for a living was enough to keep me mentally stimulated for more\nthan a decade, but once I started taking on more leadership responsibilities it\ndidnâ€™t take long before I felt my skills begin to atrophy.\nThis is something I have heard people more senior than myself talk about my\nentire career, but when it started happening to me it felt terrifying. If I lost\nmy ability to do the thing that had gotten me to this point in the first place,\nhow long until Iâ€™m no longer useful to the people Iâ€™m entrusted to lead?\nThis may all sound a bit melodramatic, but itâ€™s been gnawing at me for years\nnow. I just havenâ€™t have the time, energy, or ability to do anything to change\nit. I still love my job - and it was never really an option to go back. I found\n(and still find) it very rewarding to have more of an impact than what I could\nachieve by only writing code. However, somewhat fortuitously, the less time I\nhad to do what I truly love at work, the more time I was willing to spend my\nfree time searching for ways to reintegrate this passion into my daily life.\nGoing forward\nIâ€™ve spent the past several months rediscovering things that I had previously\nlost interest in. Simple things like building computers, installing operating\nsystems, configuring my desktop environment, and tweaking my favorite text\neditor. Itâ€™s been a lot of fun, and going forward I am going to write about them\nhere. This will mostly be a form of self-therapy and archiving for the sake of\nposterity, but Iâ€™m going to do this publicly in the off chance that someone else\nfinds anything I have to say interesting or useful. Thatâ€™s it for now. Thank you\nif youâ€™ve decided to read this far, and have a nice day."},"posts/02-how-i-made-this-website":{"slug":"posts/02-how-i-made-this-website","filePath":"posts/02-how-i-made-this-website.md","title":"How I made this website","links":["posts/01-my-first-post"],"tags":[],"content":"In my last post (which also happened to be My first post) I provided a little bit of context as to why I made this website. Now that Iâ€™ve gotten that over with, Iâ€™m going to continue on my merry way and pontificate on random and mostly technical things that I have been occupying my time. I figured a good place to start would be to capture how I made this website.\nMarkdown, please\nAs Iâ€™ve gotten older, Iâ€™ve begun to care more about retaining full control of my data. Iâ€™ve also developed more of a propensity towards simplicity, and that involves searching out things that Iâ€™m able to understand and easily navigate. Tools that just get out of my way. At this point, writing in Markdown has become second nature. I find myself using it even I donâ€™t mean to.\nObsidian\nI think most developers have heard of Obsidian by now - an application for writing and managing content in Markdown. Anyone who has written a lot of Markdown-based content will know that it can become unwieldy to manage over time, especially when linking between documents and using some more of its advanced features like tables. Obsidian makes these things easy, with real-time previews and the ability to automatically update links when you move things around.\nQuartz\nWhile Obsidian has its own (paid) option to publish to a website hosted on their servers, it is after all just a directory full of files. While there are several static website generators out there that support Markdown, none are quite as polished as Quartz- which also happens to be Obsidian compatible out of the box. If you havenâ€™t seen Quartz before, I could not recommend it enough - itâ€™s fast, has an extremely powerful search feature, live reloading, and is pretty much infinitely flexible if youâ€™re willing to spend a little time learning TypeScript.\nRunning Quartz locally\nAs much as I love Quartz, I did not love how their documentation currently instructs users to clone the repository locally, install NodeJS, and store content within a fork of the Quartz project.\nCustom tooling\nTo prevent installing Node on my computer, I put together a custom Containerfile that installs the necessary dependencies and clones the Quartz repo:\nFROM registry.fedoraproject.org/fedora\n \nARG QUARTZ_REF=eccad3da5d7b84b0f78a85b357efedef8c0127fc\n \nUSER root\n \nRUN dnf install -y git make nodejs &amp;&amp; \\\n    npm install -g n &amp;&amp; \\\n    n lts &amp;&amp; \\\n    npm install -g npm@latest &amp;&amp; \\\n    dnf remove -y nodejs\n \nRUN git config --global --add safe.directory /repo\nRUN cd /opt &amp;&amp; git clone github.com/jackyzha0/quartz.git &amp;&amp; \\\n    cd quartz &amp;&amp; git checkout ${QUARTZ_REF} &amp;&amp; \\\n    npm ci\n \nCOPY quartz.config.ts /opt/quartz/\nCOPY quartz.layout.ts /opt/quartz/\n \nWORKDIR /opt/quartz\nNote here how I clone Quartz into the image and only COPY the files that I need to customize.\nWhy am I currently using a random SHA rather than a tagged version? While I was in the process of building out this website I came across this issue - although they didnâ€™t end up accepting my PR, Iâ€™m grateful that the maintainers of Quartz were willing to collaborate and fix the underlying problem.\nMake it simple\nSome things are just better off not being rewritten in JavaScript. I think Make is one of these things. It might have first came out closer to the Moon landing than when I built this website, but itâ€™s still more powerful than anything thatâ€™s been written in recent years and itâ€™s way less likely to be abandoned as the project some dude wrote over the weekend and shared on Hacker News.\nSee the full version of my Makefile for this website for more information, but the gist of it is here:\n.DEFAULT_GOAL := scratchpad\n \n.PHONY: scratchpad\nscratchpad: check_image_uptodate\n\t@$(CONTAINER_RUNTIME) run --rm -ti \\\n\t\t-p $(QUARTZ_SERVER_PORT):$(QUARTZ_SERVER_PORT) \\\n\t\t-p $(QUARTZ_WEBSOCKET_PORT):$(QUARTZ_WEBSOCKET_PORT) \\\n\t\t$(COMMON_MOUNTS) \\\n\t\t$(SCRATCHPAD_IMAGE_NAME) \\\n \n.PHONY: check_image_uptodate\ncheck_image_uptodate: image\n\t@echo &quot;Checking current image SHA...&quot;\n\t@current_sha=$$($(CONTAINER_RUNTIME) inspect --format=&#039;{{.Id}}&#039; $(SCRATCHPAD_IMAGE_NAME):$(IMAGE_TAG) 2&gt;/dev/null || echo &quot;none&quot;); \\\n\tstored_sha=$$(cat $(IMAGE_ID_FILE) 2&gt;/dev/null || echo &quot;none&quot;); \\\n\tif [ &quot;$$current_sha&quot; != &quot;$$stored_sha&quot; ] || [ -z &quot;$$current_sha&quot; ]; then \\\n\t\techo &quot;Building image... $$current_sha $$stored_sha&quot;; \\\n\t\t$(MAKE) -B -f $(MAKEFILE_PATH) image; \\\n\telse \\\n\t\techo &quot;Image is up to date.&quot;; \\\n\tfi\n \n.PHONY: image\nimage: $(IMAGE_ID_FILE)\n \n$(IMAGE_ID_FILE): .generated Containerfile quartz.config.ts quartz.layout.ts\n\t$(CONTAINER_RUNTIME) build -t $(SCRATCHPAD_IMAGE_NAME):$(IMAGE_TAG) .\n\t$(CONTAINER_RUNTIME) inspect --format=&#039;{{.Id}}&#039; $(SCRATCHPAD_IMAGE_NAME):$(IMAGE_TAG) &gt; $(IMAGE_ID_FILE)\nThe result here is that on a machine with just make and podman (or docker) installed, I can simply clone this repo and run the command:\nâžœ  shanemcd.github.io git:(main) âœ— make\nChecking current image SHA...\nImage is up to date.\nnpx quartz build --serve --port=6006 --directory=/repo/content\n\n Quartz v4.5.0\n\nCleaned output directory `public` in 2ms\nFound 4 input files from `/repo/content` in 5ms\nParsed 4 Markdown files in 112ms\nFiltered out 0 files in 24Î¼s\nEmitted 16 files to `public` in 71ms\nDone processing 4 files in 191ms\nStarted a Quartz server listening at http://localhost:6006\n\nThis handles building (and rebuilding) the container image, starting serving Quartz, mounting in the site content, and mapping ports for the web server and live-reload websocket.\nDeploying via GitHub Pages\nMost people are familiar with using GitHub Pages to host a Jekyll website, but it is also possible to serve up a pre-built HTML website that has been pushed to a branch. To automate this process I threw together this GitHub Action:\n# Simple workflow for deploying static content to GitHub Pages\nname: Deploy static content to Pages\n \npermissions:\n  contents: write\n \non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [&quot;main&quot;]\n \n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: &quot;pages&quot;\n  cancel-in-progress: false\n \nenv:\n  CONTAINER_RUNTIME: docker\n  RUN_CMD: &gt;-\n    QUARTZ_BUILD_OPTS=&#039;-o /repo/public&#039; make -f /repo/Makefile public\n \njobs:\n  # Single deploy job since we&#039;re just deploying\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n \n      - name: Build site\n        run: make run\n \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: public\n \n      - name: Deploy ðŸš€\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          folder: public\n          branch: gh-pages\n          clean-exclude: pr-preview\n          force: false\nPreviewing changes\nI might be lazy, but I also love finding a good problem to over-engineer. I had originally done this for a project at work, but was able to reuse here without much effort.\nUnfortunately GitHub Pages does not natively support previewing changes. It seems like that will come at some point, but itâ€™s been almost 5 years and thereâ€™s still ETA. Luckily the Deploy PR Preview action will do just fine for now.\nHere is how Iâ€™m using it. The only thing Iâ€™ve changed is an additional invocation of marocchino/sticky-pull-request-comment, which I found rossjrw/pr-preview-action uses under the hood. I update the comment it posts to add a little reminder that the link will only work once the Action completes.\n---\nname: preview\n \npermissions:\n  contents: write\n  pull-requests: write\n \nconcurrency: preview-${{ github.ref }}\n \non:\n  pull_request_target:\n    types:\n      - opened\n      - reopened\n      - synchronize\n      - closed\n \nenv:\n  CONTAINER_RUNTIME: docker\n  RUN_CMD: &gt;-\n    QUARTZ_BUILD_OPTS=&#039;-o /repo/public&#039; make -f /repo/Makefile public\n \njobs:\n  preview:\n    runs-on: ubuntu-20.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n        with:\n          ref: refs/pull/${{ github.event.pull_request.number }}/merge\n          fetch-depth: 0\n \n      - run: |\n          git log\n \n      - name: Build site\n        if: github.event.action != &#039;closed&#039;\n        run: make run\n \n      - name: Deploy preview\n        uses: rossjrw/pr-preview-action@v1\n        with:\n          source-dir: public\n \n      - name: Update preview comment with note about being patient\n        uses: marocchino/sticky-pull-request-comment@v2\n        with:\n          header: pr-preview\n          append: true\n          message: |\n            &gt; [!IMPORTANT]\n            &gt; The link above will not work until the Pages deployment is complete. You can find this under [Actions -&gt; pages-build-deployment](github.com/andyettanotherorg/shanemcd.github.io/actions/workflows/pages/pages-build-deployment).\nWhich looks like this:\n\nThis might be overkill, but it lets me test things out without iterating directly on my main branch and helps for cases where I might not have access to Obsidian or the ability to test a site build locally.\nWrapping up\nI mostly captured this for my own posterity, but if for whatever reason you find yourself wanting to learn more please about any of this please check out the source for this website. If you have any questions or just want to say hi, my email is on my GitHub profile."},"posts/03-ollama-rootless-podman-quadlet":{"slug":"posts/03-ollama-rootless-podman-quadlet","filePath":"posts/03-ollama-rootless-podman-quadlet.md","title":"Running Ollama under Rootless Podman with Quadlet","links":[],"tags":[],"content":"I havenâ€™t seen any instances of other people running Ollama quite like this, so I thought I would share in case it proves to be useful for anyone else out there.\nFor those not familiar with Quadlet, it provides functionality that allows you to run and manage containers with systemd.\nNVIDIA GPU support\nBefore we can run Ollama inside of a container we first need to install the NVIDIA Container Toolkit as described here.\nGenerating the CDI specification file\nThe documentation here shows running this command manually. Given this will likely need to be re-ran over time and it is safe to re-invoke multiple times, I decided to wrap this up in a systemd unit that runs once every time my machine boots:\n[Unit]\nDescription=Generate NVIDIA CDI configuration\n \n[Service]\nType=oneshot\nExecStart=/usr/bin/nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml\nRemainAfterExit=yes\n \n[Install]\nWantedBy=multi-user.target\nPlace this in /etc/systemd/system/nvidia-cdi-generator.service and run these commands as root:\n$ systemctl daemon-reload\n$ systemctl enable --now nvidia-cdi-generator.service\n\nOllama with Podman and Quadlet\nNow that we can talk to our NVIDIA GPU from within a container, we can create a Quadlet in ~/.config/containers/systemd/ollama.container:\n[Unit]\nDescription=My Llama\nRequires=nvidia-cdi-generator\nAfter=nvidia-cdi-generator\n \n[Container]\nImage=docker.io/ollama/ollama\nAutoUpdate=registry\nPodmanArgs=--privileged --gpus=all\nEnvironment=NVIDIA_VISIBLE_DEVICES=all\nVolume=%h/.ollama:/root/.ollama\nPublishPort=11434:11434\n \n[Service]\nRestart=always\n \n[Install]\nWantedBy=default.target\nStart it by:\n$ systemctl --user daemon-reload\n$ systemctl --user start ollama.service\n\nVerify itâ€™s running by viewing the logs:\n$ journalctl --user -xeu ollama\n"},"posts/04-jetkvm-tailscale":{"slug":"posts/04-jetkvm-tailscale","filePath":"posts/04-jetkvm-tailscale.md","title":"Getting Tailscale to work on my JetKVM","links":[],"tags":[],"content":"Earlier this week I got my JetKVM in the mail. Thereâ€™s plenty of posts out there about how awesome it is, so I wonâ€™t bother to write another post reiterating that. Well, maybe briefly: it is in fact awesome. You should by one.\nRemotely accessing my JetKVM\nWhile the folks behind this product seem smart enough, Iâ€™m always skeptical about using new cloud services, especially when they have a direct line to my PC. Rather than use their Remote Access feature, I was happy to see that they also had a link in their FAQ pointing to an article on Medium called Installing Tailscale on JetKVM. This unfortunately did not work for me without some minor tweaks.\nGetting Tailscale to start automatically\nBecause JetKVM is built on top of busybox (for better or worse - worse IMHO), it lacks a modern init system. Other than being a good introduction for less experienced folks into how things used to be before systemd, it is a bit of a pain to work with.\nAnyway, after using the script shared in the Medium post linked above, the first thing I noticed was that upon reboot my device did not rejoin my tailnet.\nAfter adding some basic logging to the init script, I was able to see that it was crashing due to the TUN device not being available:\nwgengine.NewUserspaceEngine(tun &quot;tailscale0&quot;) error: tstun.New(&quot;tailscale0&quot;): CreateTUN(&quot;tailscale0&quot;) failed; /dev/net/tun does not exist\nflushing log.\nlogger closing down\nlogtail: upload: log upload of 942 bytes compressed failed: Post &quot;log.tailscale.com/c/tailnode.log.tailscale.io/986ca5896dc4d4b0b3de7618f45bf030588040a882f53c226de82ebe42fc0c5f&quot;: context canceled\nlogtail: dial &quot;log.tailscale.com:443&quot; failed: dial tcp: lookup log.tailscale.com: operation was canceled (in 1.022s), trying bootstrap...\ngetLocalBackend error: createEngine: tstun.New(&quot;tailscale0&quot;): CreateTUN(&quot;tailscale0&quot;) failed; /dev/net/tun does not exist\n\nStrangely, simply re-running this script resolved the issue and Tailscale started fine. This led me to the realization that the tun kernel module needed to be loaded ahead of time.\nHere is my version of the init script that adds some basic logging and checks and ensures that /dev/net/tun exists before trying to start tailscaled:\n#!/bin/sh\nlog=&quot;/tmp/ts.log&quot;\n \necho &quot;$(date): S22tailscale script starting with arg: $1&quot; &gt;&gt; $log\n \nwait_for_tun() {\n  modprobe tun 2&gt;&gt;$log\n  for i in $(seq 1 10); do\n    [ -e /dev/net/tun ] &amp;&amp; return 0\n    echo &quot;$(date): /dev/net/tun not ready, retrying...&quot; &gt;&gt; $log\n    sleep 1\n  done\n  echo &quot;$(date): /dev/net/tun still not present after waiting&quot; &gt;&gt; $log\n  return 1\n}\n \nwait_for_network() {\n  for i in $(seq 1 10); do\n    ip route | grep default &gt;/dev/null &amp;&amp; return 0\n    echo &quot;$(date): no default route yet, retrying...&quot; &gt;&gt; $log\n    sleep 1\n  done\n  echo &quot;$(date): still no default route after waiting&quot; &gt;&gt; $log\n  return 1\n}\n \ncase &quot;$1&quot; in\n  start)\n    wait_for_tun || exit 1\n    wait_for_network || exit 1\n    echo &quot;$(date): Starting tailscaled...&quot; &gt;&gt; $log\n    TS_DEBUG_FIREWALL_MODE=nftables /userdata/tailscale/tailscaled \\\n      -statedir /userdata/tailscale-state &gt;&gt; $log 2&gt;&amp;1 &amp;\n    ;;\n  stop)\n    echo &quot;$(date): Stopping tailscaled...&quot; &gt;&gt; $log\n    killall tailscaled &gt;&gt; $log 2&gt;&amp;1\n    ;;\n  *)\n    echo &quot;Usage: $0 {start|stop}&quot; &gt;&amp;2\n    exit 1\n    ;;\nesac\nOrthogonal issue with non-persistent MAC address\nDuring the process of setting up my JetKVM, I noticed that I was getting a new IP every time the device restarted. The first thing I tried was to give in a static IP through my UniFi console, but was surprised when after a reboot I got yet another IP. This led to me finding this GitHub issuethat has a ton of activity on it. I suspect this will be fixed soon, but in the meantime, this comment had a solution that resolves the issue."},"posts/05-kind-podman-exec-as-root":{"slug":"posts/05-kind-podman-exec-as-root","filePath":"posts/05-kind-podman-exec-as-root.md","title":"Obtaining root access in a pod running under kind on podman","links":[],"tags":[],"content":"I am using a development environment that utilizes kind running under rootless Podman. Hereâ€™s how I was able to save some time while debugging and avoid needing to rebuild/redeploy when testing changes to containers that are not running as root.\nFirst, we need to exec from our host into the kind container:\n$ podman exec -ti kind-control-plane bash\n\nNext, locate the container we want to access:\nroot@kind-control-plane:/# crictl ps | grep api \n46fc42d2ed03c Â Â Â Â Â Â 09ba385429956 Â Â Â Â Â Â 16 minutes ago Â Â Â Â Â Running Â Â Â Â Â Â Â Â Â Â Â Â api Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 8f72c70f538a5 Â Â Â Â Â Â my-app-8544786747-rzwlp Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â default\n\nObtain the full ID:\nroot@kind-control-plane:/# crictl inspect 46fc42d2ed03c | jq -r &#039;.status.id&#039;  \n46fc42d2ed03c7e42452725bcdea05c089958b1d2c62f4d68526c2640e8cab8a\n\nNow we can gain root access to our container:\nroot@kind-control-plane:/# ctr --namespace k8s.io tasks exec --user 0 --exec-id debug --tty 46fc42d2ed03c7e42452725bcdea05c089958b1d2c62f4d68526c2640e8ca  \nb8a /bin/sh  \nsh-4.4# id -u Â Â   \n0\n\nðŸ¤˜"},"posts/index":{"slug":"posts/index","filePath":"posts/index.md","title":"Posts","links":[],"tags":[],"content":"These are things Iâ€™ve written."}}